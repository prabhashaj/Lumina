# AI Research Teaching Agent

<div align="center">
  <h1>ğŸ§  AI Research Teaching Agent</h1>
  <p><strong>Production-Grade Multi-Agent System for Intelligent Learning</strong></p>
  <p>Combining real-time web search with AI-powered teaching to transform how students learn</p>
</div>

## ğŸŒŸ Overview

This is a complete, production-ready AI teaching assistant that doesn't just answer questionsâ€”it researches, synthesizes, and teaches. Built with a sophisticated multi-agent architecture using LangGraph, it orchestrates multiple AI agents to deliver comprehensive, pedagogically sound learning experiences.

### What Makes This Different

- **Multi-Agent Orchestration**: Not a simple chatbotâ€”multiple specialized AI agents working together
- **Real-Time Web Research**: Searches the web live using Tavily API for current, accurate information
- **Exam Prep Mode**: Complete exam preparation with structured roadmaps, quizzes, and progress tracking
- **Document & Image Upload**: Analyze images and extract content from PDFs, DOCX, and text files
- **Educational Focus**: Designed by considering learning psychology and pedagogy
- **Visual Learning**: Analyzes and incorporates relevant images and diagrams
- **Adaptive Difficulty**: Automatically adjusts explanations to student level
- **Source Citations**: Every factual claim is backed by credible sources
- **Streaming UI**: Real-time updates as each agent completes its work
- **Text-to-Speech**: Listen to explanations with AI-powered voice synthesis

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Student Question                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LangGraph Orchestrator                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. Intent Classifier Agent                          â”‚  â”‚
â”‚  â”‚     â€¢ Difficulty (beginner/intermediate/advanced)    â”‚  â”‚
â”‚  â”‚     â€¢ Question type (conceptual/practical/math)      â”‚  â”‚
â”‚  â”‚     â€¢ Learning needs (visuals, code, etc.)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  2. Web Search Agent (Tavily)                        â”‚  â”‚
â”‚  â”‚     â€¢ Multi-query search strategy                    â”‚  â”‚
â”‚  â”‚     â€¢ Source ranking & filtering                     â”‚  â”‚
â”‚  â”‚     â€¢ Image collection                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  3. Content Extraction Agent                         â”‚  â”‚
â”‚  â”‚     â€¢ Clean text extraction                          â”‚  â”‚
â”‚  â”‚     â€¢ Relevance filtering                            â”‚  â”‚
â”‚  â”‚     â€¢ Source credibility assessment                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  4. Image Understanding Agent (VLM)                  â”‚  â”‚
â”‚  â”‚     â€¢ Image captioning                               â”‚  â”‚
â”‚  â”‚     â€¢ Diagram understanding                          â”‚  â”‚
â”‚  â”‚     â€¢ Relevance scoring                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  5. Teaching Synthesis Agent                         â”‚  â”‚
â”‚  â”‚     â€¢ Comprehensive explanation                      â”‚  â”‚
â”‚  â”‚     â€¢ Analogies & examples                           â”‚  â”‚
â”‚  â”‚     â€¢ Practice questions                             â”‚  â”‚
â”‚  â”‚     â€¢ Adaptive language                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â”‚                                    â”‚
â”‚                         â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  6. Quality Assessment                               â”‚  â”‚
â”‚  â”‚     â€¢ Completeness check                             â”‚  â”‚
â”‚  â”‚     â€¢ Accuracy verification                          â”‚  â”‚
â”‚  â”‚     â€¢ Retry logic if quality < threshold             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Comprehensive Teaching Response                 â”‚
â”‚  â€¢ TL;DR â€¢ Step-by-step explanation â€¢ Visual aids           â”‚
â”‚  â€¢ Analogies â€¢ Practice questions â€¢ Source citations        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI**: Modern, high-performance Python web framework
- **LangChain**: LLM application framework
- **LangGraph**: Multi-agent orchestration and workflow
- **OpenAI GPT-4**: Primary language model
- **Tavily API**: Advanced web search
- **Redis**: Response caching
- **FAISS**: Vector database for semantic search
- **Replicate**: Vision Language Model hosting

### Frontend
- **Next.js 14**: React framework with App Router
- **TypeScript**: Type-safe development
- **Tailwind CSS**: Utility-first styling
- **shadcn/ui**: High-quality UI components
- **Server-Sent Events**: Real-time streaming

### Optional Dependencies
- **PyPDF2**: PDF text extraction
- **python-docx**: DOCX text extraction
- **httpx**: HTTP client for ElevenLabs TTS API

## âœ¨ Feature Comparison

| Feature | Research Mode | Exam Prep Mode |
|---------|---------------|----------------|
| AI-Powered Explanations | âœ… | âœ… |
| Real-time Web Search | âœ… | âœ… |
| Image Analysis | âœ… | âœ… |
| Source Citations | âœ… | âœ… |
| Practice Questions | âœ… | âœ… |
| Structured Roadmap | âŒ | âœ… |
| Quiz Generation | âŒ | âœ… |
| Progress Tracking | âŒ | âœ… |
| Sequential Learning | âŒ | âœ… |
| Document Upload | âœ… | âœ… |
| Text-to-Speech | âœ… | âœ… |

## ğŸš€ Getting Started

### âš¡ Quick Start

The fastest way to get started:

**Windows:**
```bash
# Clone and navigate to project
cd ai-research-agent

# Run the quickstart script
.\quickstart.bat
```

**Mac/Linux:**
```bash
# Clone and navigate to project
cd ai-research-agent

# Make script executable and run
chmod +x quickstart.sh
./quickstart.sh
```

The quickstart script will:
1. Set up Python virtual environment
2. Install all dependencies
3. Create `.env` files from templates
4. Start both backend and frontend servers

**Then:** Add your API keys to `backend/.env` and refresh!

> ğŸ“ For detailed step-by-step instructions, see [SETUP.md](SETUP.md)

### Prerequisites

```bash
# Required
- Python 3.10+
- Node.js 18+
- npm or yarn

# Optional but recommended
- Redis (for caching)
```

### API Keys Needed

#### Required:
1. **OpenAI API Key** - [Get it here](https://platform.openai.com/api-keys)
   - Used for: Main LLM processing, intent classification, teaching synthesis
   - Cost: ~$0.01-0.10 per question (GPT-4)

2. **Tavily API Key** - [Get it here](https://tavily.com/)
   - Used for: Real-time web search
   - Cost: Free tier available, sufficient for testing

#### Optional (for enhanced features):
3. **Replicate API Token** - [Get it here](https://replicate.com/)
   - Used for: Vision Language Model (image understanding)
   - Feature: Analyze uploaded images and diagrams
   
4. **ElevenLabs API Key** - [Get it here](https://elevenlabs.io/)
   - Used for: High-quality text-to-speech
   - Feature: AI voice narration (falls back to browser TTS if not available)

### Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Optional: Install file processing dependencies
pip install PyPDF2 python-docx

# Create .env file
cp .env.example .env

# Edit .env and add your API keys
# Required: OPENAI_API_KEY, TAVILY_API_KEY
# Optional: REPLICATE_API_TOKEN

# Run the server
python main.py
```

The backend will start at `http://localhost:8000`

### Frontend Setup

```bash
# Navigate to frontend directory  
cd frontend

# Install dependencies
npm install

# Create environment file
cp .env.local.example .env.local

# Run development server
npm run dev
```

The frontend will start at `http://localhost:3000`

## ğŸ“– Usage

### Research Mode

1. **Open** `http://localhost:3000` in your browser
2. **Select "Research" mode** (default)
3. **Ask any question** you want to learn about
4. **Optional**: Upload an image or document for context
5. **Watch** as the system:
   - Analyzes your question
   - Searches the web in real-time
   - Processes images and sources
   - Synthesizes a comprehensive explanation
6. **Learn** from:
   - TL;DR summary
   - Step-by-step explanation
   - Visual aids with captions
   - Real-world analogies
   - Practice questions
   - Cited sources

### Exam Prep Mode ğŸ“

1. **Click "Exam Prep"** in the header
2. **Enter your exam subject** (e.g., "Organic Chemistry", "Machine Learning")
3. **Generate Roadmap**: AI creates a structured chapter-wise syllabus
4. **Study Topics**: Click any topic to get comprehensive content with:
   - Detailed explanations
   - Visual aids and diagrams
   - Practice questions
   - Source citations
5. **Take Quizzes**: Test your knowledge with 5 multiple-choice questions per topic
6. **Track Progress**: Unlock topics sequentially by passing quizzes (60% required)
7. **Save & Resume**: All progress saved locally in your browser

### Example Questions

**Research Mode:**
- "Explain quantum entanglement"
- "How do neural networks learn?"
- "What is the water cycle?"
- "Explain derivatives in calculus with examples"
- "How does blockchain work?"
- Upload a diagram and ask "Explain this image"
- Upload lecture notes and ask "Summarize the key concepts"

**Exam Prep Mode:**
- "Machine Learning" - generates complete ML syllabus with neural networks, algorithms, etc.
- "Organic Chemistry" - creates roadmap covering reactions, mechanisms, spectroscopy
- "Data Structures" - structured topics from arrays to graphs and trees
- "World History" - chronological chapters covering major eras and events

## ğŸ¯ Key Features

### 1. **Research Mode**
Ask any question and get comprehensive, source-backed explanations
- Automatically detects difficulty level
- Adjusts language and depth accordingly
- Provides beginner, intermediate, or advanced explanations

### 2. **Exam Prep Mode** ğŸ“
Complete exam preparation system with structured learning
- **Roadmap Generation**: AI creates chapter-wise syllabus for any subject
- **Topic Content**: Comprehensive explanations for each topic with images and sources
- **Quiz Generation**: 5 multiple-choice questions per topic with explanations
- **Progress Tracking**: Unlock topics sequentially as you complete quizzes
- **Local Storage**: All progress saved in browser

### 3. **Document & Image Upload** ğŸ“
- **Image Analysis**: Upload images and get AI-powered descriptions using Vision Language Models
- **Document Processing**: Extract and analyze text from PDFs, DOCX, TXT, MD, CSV files
- **Context Integration**: Uploaded content is integrated into research queries

### 4. **Visual Learning**
- Finds relevant images and diagrams
- Captions explain what each image teaches
- Ranks images by educational value
- VLM-powered image understanding

### 5. **Multi-Modal Teaching**
- Text explanations with structured sections
- Visual aids with educational captions
- Analogies and metaphors for complex concepts
- Practice questions for active recall
- Source citations for credibility
- Text-to-Speech for audio learning

### 6. **Quality Assurance**
- Assesses response completeness
- Retries search if quality is low
- Verifies factual accuracy against sources
- Maximum 3 retry attempts

### 7. **Streaming UI**
- Real-time status updates
- Progressive content loading
- Smooth, ChatGPT-like experience
- No waiting for full response

### Personalized Mode
Tailors the learning experience to each user by creating adaptive, data-driven learning plans and tracking progress over time.

- **Adaptive Learning Paths:** Automatically generates a personalized roadmap based on the user's goals, strengths, and weaknesses. Topics are ordered and paced to optimize mastery.
- **Dynamic Difficulty:** Questions, explanations, and examples are adjusted to the user's current competency level and updated as they improve.
- **Personalized Assessments:** Generates quizzes and practice questions specific to the user's learning path, with automatic scoring, explanations, and remediation suggestions.
- **Spaced Repetition & Review:** Integrated review scheduling surfaces previously learned items at optimal intervals to improve long-term retention.
- **Visual & Contextual Recommendations:** Prioritizes relevant images, diagrams, and example-driven explanations tailored to the learner's needs.
- **Progress Dashboard:** Track mastery, streaks, time spent, and recommended next steps. Export progress or download study summaries.
- **Privacy-first Sync:** Local-first storage for learning state with optional encrypted cloud sync for cross-device continuity.
- **Teacher / Mentor Mode:** Instructors can seed curricula, review learner progress, and share curated content (optional administrator features).

Technical notes:
- Frontend: `PersonalizedMode` UI components live in the frontend and connect to the user's profile and local storage to render plans, quizzes, and progress visuals.
- Backend: Personalization relies on user profiles, vector embeddings (FAISS), and a scoring engine that ranks topics and items by relevance and mastery. Spaced-repetition scheduling and assessment grading run on backend services (or in-browser for offline-first setups).
- Data: All personalization signals (answers, quiz performance, time-on-task) are stored to improve recommendations; defaults favor local storage unless the user opts into cloud sync.


## ğŸ§ª API Documentation

### Research Endpoints

#### `POST /api/research`
Complete research request (returns full response)

```typescript
// Request
{
  "question": "string",
  "conversation_history": [],  // optional
  "user_id": "string",  // optional
  "image_context": "string",  // optional, from image upload
  "file_context": "string"  // optional, from file upload
}

// Response
{
  "question": "string",
  "tldr": "string",
  "explanation": {...},
  "images": [...],
  "sources": [...],
  "analogy": "string",
  "practice_questions": [...],
  "difficulty_level": "beginner|intermediate|advanced",
  "confidence_score": 0.85,
  "processing_time": 5.23
}
```

#### `POST /api/research/stream`
Streaming research (Server-Sent Events)

Returns progressive updates:
- `status`: Current agent activity
- `intent`: Question analysis results
- `tldr`: Quick summary
- `explanation`: Full explanation
- `image`: Individual images
- `source`: Individual sources
- `complete`: Final full response

### File Upload Endpoints

#### `POST /api/upload/image`
Upload and analyze an image with Vision Language Model

```typescript
// Form Data Request
{
  file: File,  // Image file (JPEG, PNG, GIF, WebP)
  question: string  // Optional context question
}

// Response
{
  "filename": "string",
  "content_type": "string",
  "analysis": "string",  // VLM description
  "preview_url": "string"  // Base64 data URL
}
```

#### `POST /api/upload/file`
Upload and extract text from documents

```typescript
// Form Data Request
{
  file: File  // PDF, DOCX, TXT, MD, or CSV
}

// Response
{
  "filename": "string",
  "content_type": "string",
  "extracted_text": "string",
  "char_count": number
}
```

### Exam Prep Endpoints

#### `POST /api/exam-prep/roadmap`
Generate a structured study roadmap for any subject

```typescript
// Request
{
  "subject": "string"  // e.g., "Machine Learning", "Organic Chemistry"
}

// Response
{
  "subject": "string",
  "chapters": [
    {
      "title": "string",
      "description": "string",
      "topics": ["string", "string", ...]
    }
  ]
}
```

#### `POST /api/exam-prep/topic-content/stream`
Stream comprehensive content for a specific topic (SSE)

```typescript
// Request
{
  "subject": "string",
  "chapter": "string",
  "topic": "string"
}

// Streams: status, topic, tldr, explanation, images, sources, analogy, practice_questions
```

#### `POST /api/exam-prep/quiz`
Generate a quiz with 5 multiple-choice questions for a topic

```typescript
// Request
{
  "subject": "string",
  "chapter": "string",
  "topic": "string"
}

// Response
{
  "questions": [
    {
      "id": "string",
      "question": "string",
      "options": ["A", "B", "C", "D"],
      "correctIndex": number,
      "explanation": "string"
    }
  ]
}
```

### Utility Endpoints

#### `POST /api/tts`
Convert text to speech using ElevenLabs API

```typescript
// Request
{
  "text": "string"  // Text to convert (max 5000 chars)
}

// Response: Audio stream (MP3)
// Header: X-Use-Browser-TTS: "true" if ElevenLabs not available
```

#### `GET /api/config`
Get current system configuration

```typescript
// Response
{
  "max_search_results": number,
  "max_images_per_response": number,
  "features": {
    "tts_enabled": boolean,
    "vlm_enabled": boolean,
    "file_upload": boolean
  }
}
```

## ğŸ”§ Configuration

### Backend Configuration (`backend/.env`)

```env
# Required API Keys
OPENAI_API_KEY=sk-...
TAVILY_API_KEY=tvly-...

# Optional API Keys
REPLICATE_API_TOKEN=r8_...  # For image understanding (VLM)
ELEVENLABS_API_KEY=...      # For text-to-speech

# AI Models
PRIMARY_LLM_MODEL=gpt-4-turbo-preview
FALLBACK_LLM_MODEL=gpt-3.5-turbo
EMBEDDING_MODEL=text-embedding-3-small
VLM_MODEL=yorickvp/llava-13b

# Search & Content Settings
MAX_SEARCH_RESULTS=10
MAX_IMAGES_PER_RESPONSE=6

# System Settings
CACHE_TTL=3600
MAX_RETRIES=3
API_HOST=0.0.0.0
API_PORT=8000

# TTS Settings (ElevenLabs)
TTS_VOICE_ID=21m00Tcm4TlvDq8ikWAM  # Rachel voice
TTS_MODEL=eleven_monolingual_v1

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/app.log
```

### Frontend Configuration (`frontend/.env.local`)

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ“Š Performance

### Research Mode
- **Average response time**: 5-8 seconds for comprehensive answers
- **Concurrent requests**: Up to 100+ with async processing
- **Cache hit ratio**: 70%+ with Redis (when configured)
- **Search quality**: Advanced Tavily search with 10+ sources
- **Accuracy**: Source-verified responses with credibility scoring

### Exam Prep Mode
- **Roadmap generation**: 3-5 seconds for complete syllabus (5-8 chapters)
- **Topic content**: 6-10 seconds (leverages full research pipeline)
- **Quiz generation**: 2-4 seconds for 5 MCQs with explanations
- **Progress tracking**: Instant local storage updates

### File Processing
- **Image analysis**: 2-4 seconds with VLM (Vision Language Model)
- **PDF extraction**: 1-3 seconds (up to 20 pages)
- **DOCX extraction**: <1 second for standard documents
- **Text-to-Speech**: 1-2 seconds for standard responses (ElevenLabs)

## ğŸ§° Development

### Project Structure

```
ai-research-agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/              # Individual AI agents
â”‚   â”‚   â”œâ”€â”€ intent_classifier.py
â”‚   â”‚   â”œâ”€â”€ search_agent.py
â”‚   â”‚   â”œâ”€â”€ content_extraction.py
â”‚   â”‚   â”œâ”€â”€ image_understanding.py
â”‚   â”‚   â””â”€â”€ teaching_synthesis.py
â”‚   â”œâ”€â”€ graph/               # LangGraph orchestration
â”‚   â”‚   â””â”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ config/              # Configuration
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ pytest.ini           # Test configuration
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/                 # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â”œâ”€â”€ ChatInterface.tsx
â”‚   â”‚   â”œâ”€â”€ MessageList.tsx
â”‚   â”‚   â”œâ”€â”€ MessageBubble.tsx
â”‚   â”‚   â”œâ”€â”€ ChatHistorySidebar.tsx
â”‚   â”‚   â””â”€â”€ exam-prep/       # Exam preparation components
â”‚   â”‚       â”œâ”€â”€ ExamPrepMode.tsx
â”‚   â”‚       â”œâ”€â”€ QuizView.tsx
â”‚   â”‚       â”œâ”€â”€ RoadmapView.tsx
â”‚   â”‚       â””â”€â”€ TopicContentView.tsx
â”‚   â”œâ”€â”€ lib/                 # Utilities
â”‚   â”‚   â”œâ”€â”€ api.ts
â”‚   â”‚   â”œâ”€â”€ types.ts
â”‚   â”‚   â”œâ”€â”€ chatHistory.ts
â”‚   â”‚   â””â”€â”€ examPrepStorage.ts
â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â””â”€â”€ globals.css
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ schemas/             # Shared data models
â”‚   â”‚   â””â”€â”€ models.py
â”‚   â””â”€â”€ prompts/             # Prompt templates
â”‚       â””â”€â”€ templates.py
â”œâ”€â”€ README.md
â”œâ”€â”€ SETUP.md             # Detailed setup guide
â”œâ”€â”€ DEVELOPMENT.md       # Development guide
â””â”€â”€ PROJECT_SUMMARY.md   # Project overview
```

### Adding New Agents

1. Create agent file in `backend/agents/`
2. Implement agent class with async methods
3. Add node to LangGraph in `orchestrator.py`
4. Define edges and conditional routing
5. Update state model if needed

### Running Tests

```bash
# Navigate to backend directory
cd backend

# Run all tests
pytest

# Run with coverage
pytest --cov=agents --cov-report=html

# Run specific test file
pytest test_agents.py -v
```

## ğŸš€ Deployment

### Backend (FastAPI)

```bash
# Using Uvicorn
uvicorn main:app --host 0.0.0.0 --port 8000

# Using Docker
docker build -t ai-research-agent-backend .
docker run -p 8000:8000 ai-research-agent-backend

# Production with Gunicorn
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker
```

### Frontend (Next.js)

```bash
# Build for production
npm run build

# Start production server
npm start

# Deploy to Vercel
vercel deploy
```

## ğŸ“ Educational Principles

This system is built on solid educational principles:

1. **Scaffolding**: Breaks complex concepts into manageable steps
2. **Multimodal Learning**: Combines text, visuals, and analogies
3. **Active Learning**: Includes practice questions
4. **Source Credibility**: Always cites authoritative sources
5. **Adaptive Difficulty**: Matches student's current level
6. **Retrieval Practice**: Encourages active recall

## ğŸ¤ Contributing

This project demonstrates production-quality code suitable for:
- Senior engineering interviews
- Portfolio projects
- Educational technology companies
- AI/ML engineer positions

## ğŸ“œ License

MIT License - feel free to use this in your portfolio!

## ğŸ¯ Use Cases

- **Students**: Learn complex topics with comprehensive explanations and prepare for exams
- **Exam Preparation**: Create structured study plans, practice with quizzes, track progress
- **Teachers**: Generate teaching materials with sources and visual aids
- **Researchers**: Quick deep-dives into new topics with source citations
- **Professionals**: Understand technical concepts quickly with adaptive explanations
- **Lifelong Learners**: Explore any subject in depth with multimodal content
- **Visual Learners**: Analyze diagrams and images with AI assistance
- **Document Analysis**: Extract insights from PDFs, papers, and lecture notes

## ğŸ’¡ Future Enhancements

- [ ] Enhanced conversation memory and context across sessions
- [ ] Spaced repetition system for long-term retention
- [ ] Interactive diagrams and simulations
- [ ] Collaborative study sessions with multiple users
- [ ] Export roadmaps and notes to PDF
- [ ] Multi-language support
- [ ] Voice input for questions
- [ ] Code execution environment for programming topics
- [ ] Integration with learning management systems (LMS)
- [ ] Performance analytics and learning insights
- [ ] Mobile app versions
- [ ] Offline mode for downloaded content

---

<div align="center">
  <p>Built with â¤ï¸ for learners everywhere</p>
  <p><strong>Production-grade â€¢ Multi-agent â€¢ Real-time â€¢ Educational â€¢ Exam Prep</strong></p>
  <p>ğŸ§  Research Mode | ğŸ“ Exam Prep | ğŸ“ File Upload | ğŸ¤ Text-to-Speech</p>
  
  <br>
  
  ### ğŸŒŸ Star this repo if you find it useful!
  
  <p>Perfect for portfolios, learning AI development, or building educational products</p>
</div>
